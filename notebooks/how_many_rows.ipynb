{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "752c35d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9636e116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bill_json_df(source: str, year, save: bool = False) -> pd.DataFrame:\n",
    "    json_files = glob.glob(os.path.join(source, \"*.json\"))\n",
    "    columns = [\n",
    "        \"bill_id\",\n",
    "        \"status\",\n",
    "        \"state\",\n",
    "        \"state_id\",\n",
    "        \"bill_number\",\n",
    "        \"bill_type\",\n",
    "        \"bill_type_id\",\n",
    "        \"body\",\n",
    "        \"body_id\",\n",
    "        \"current_body\",\n",
    "        \"current_body_id\",\n",
    "        \"title\",\n",
    "        \"description\"\n",
    "    ]\n",
    "    data = []\n",
    "    for file in json_files:\n",
    "        with open(file, \"r\") as f:\n",
    "            json_data = json.load(f)\n",
    "            row = json_data.get(\"bill\")\n",
    "            row = {col: row.get(col, None) for col in columns}\n",
    "            data.append(row)\n",
    "    response = pd.DataFrame(data)\n",
    "    if save:\n",
    "        response.to_csv(f'{year}.csv')\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4404e029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_folder(folder_path):\n",
    "    files = glob.glob(os.path.join(folder_path, \"*.json\"))\n",
    "    return [json.load(open(f)) for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18825d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../data/bills/\"#2023/MA/\"\n",
    "\n",
    "years = [\n",
    "    \"2009\",\n",
    "    \"2011\",\n",
    "    \"2013\",\n",
    "    \"2015\",\n",
    "    \"2017\",\n",
    "    \"2019\",\n",
    "    \"2020\",\n",
    "    \"2021\",\n",
    "    \"2023\",\n",
    "    \"2025\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db54ac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "courts = [\"2009-2010_186th_General_Court\",\n",
    "         \"2011-2012_187th_General_Court\",\n",
    "         \"2013-2014_188th_General_Court\",\n",
    "         \"2015-2016_189th_General_Court\",\n",
    "         \"2017-2018_190th_General_Court\",\n",
    "         \"2019-2020_191st_General_Court\",\n",
    "         \"2021-2022_192nd_General_Court\",\n",
    "         \"2023-2024_193rd_General_Court\",\n",
    "         \"2025-2026_194th_General_Court\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "697ffc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/bills/2009/MA/2009-2010_186th_General_Court/bill\n",
      "../../data/bills/2011/MA/2011-2012_187th_General_Court/bill\n",
      "../../data/bills/2013/MA/2013-2014_188th_General_Court/bill\n",
      "../../data/bills/2015/MA/2015-2016_189th_General_Court/bill\n",
      "../../data/bills/2017/MA/2017-2018_190th_General_Court/bill\n",
      "../../data/bills/2019/MA/2019-2020_191st_General_Court/bill\n",
      "../../data/bills/2020/MA/2021-2022_192nd_General_Court/bill\n",
      "../../data/bills/2021/MA/2023-2024_193rd_General_Court/bill\n",
      "../../data/bills/2023/MA/2025-2026_194th_General_Court/bill\n"
     ]
    }
   ],
   "source": [
    "#/bill\n",
    "\n",
    "for year, court in zip(years,courts):\n",
    "    full_path = path +year+\"/MA/\"+ court +\"/bill\"\n",
    "    print(full_path)\n",
    "    make_bill_json_df(full_path, year=year, save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9925663b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009.csv\t    2019_vote.csv\tgraph.ipynb\n",
      "2009_roll_call.csv  2020.csv\t\thow_many_rows.ipynb\n",
      "2009_vote.csv\t    2020_roll_call.csv\tingest_bills.py\n",
      "2011.csv\t    2020_vote.csv\tingest_performance.py\n",
      "2011_roll_call.csv  2021.csv\t\tinget_spending.py\n",
      "2011_vote.csv\t    2021_roll_call.csv\tnodes.csv\n",
      "2013.csv\t    2023.csv\t\tpeople.csv\n",
      "2013_roll_call.csv  2023_roll_call.csv\tpolitician_bill_links.csv\n",
      "2013_vote.csv\t    2025.csv\t\tpoliticians_edges.csv\n",
      "2015.csv\t    2025_roll_call.csv\tpoliticians_nodes.csv\n",
      "2015_roll_call.csv  2025_vote.csv\t__pycache__\n",
      "2015_vote.csv\t    bill.csv\t\tquick.py\n",
      "2017.csv\t    covote_edges.csv\ttest_mapping.ipynb\n",
      "2017_roll_call.csv  covote_nodes.csv\tuniques.csv\n",
      "2017_vote.csv\t    edges.csv\t\tvotes.csv\n",
      "2019.csv\t    exploratory.ipynb\n",
      "2019_roll_call.csv  graph.html\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84e81a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read: 2009.csv\n",
      "Successfully read: 2011.csv\n",
      "Successfully read: 2013.csv\n",
      "Successfully read: 2015.csv\n",
      "Successfully read: 2017.csv\n",
      "Successfully read: 2019.csv\n",
      "Successfully read: 2020.csv\n",
      "Successfully read: 2021.csv\n",
      "Successfully read: 2023.csv\n",
      "Successfully read: 2025.csv\n",
      "\n",
      "Concatenation successful. The combined DataFrame has:\n",
      "- Number of rows: 50164\n",
      "- Number of columns: 14\n"
     ]
    }
   ],
   "source": [
    "all_dfs = []\n",
    "\n",
    "for year in years:\n",
    "    filename = f\"{year}.csv\"\n",
    "    if os.path.exists(filename):\n",
    "        try:\n",
    "            df = pd.read_csv(filename)\n",
    "            all_dfs.append(df)\n",
    "            print(f\"Successfully read: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename}: {e}\")\n",
    "    else:\n",
    "        print(f\"File not found: {filename}\")\n",
    "\n",
    "if all_dfs:\n",
    "    combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    print(\"\\nConcatenation successful. The combined DataFrame has:\")\n",
    "    print(f\"- Number of rows: {len(combined_df)}\")\n",
    "    print(f\"- Number of columns: {combined_df.shape[1]}\")\n",
    "else:\n",
    "    print(\"\\nNo CSV files were successfully read, so no DataFrame was created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e9aab01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50164"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df[\"bill_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09381dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_people_json_df(source: str, year, save: bool = False) -> pd.DataFrame:\n",
    "    json_files = glob.glob(os.path.join(source, \"*.json\"))\n",
    "    columns = [\"people_id\", \"name\", \"party\", \"state_id\", \"role\", \"district\"]\n",
    "    data = []\n",
    "    for file in json_files:\n",
    "        with open(file, \"r\") as f:\n",
    "            row = json.load(f)\n",
    "            row = row.get(\"person\")\n",
    "            row = {col: row.get(col, None) for col in columns}\n",
    "            data.append(row)\n",
    "    df = pd.DataFrame(data)\n",
    "    if save:\n",
    "        df.to_csv(f\"{year}_vote.csv\", index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "022f6626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/bills/2009/MA/2009-2010_186th_General_Court/people\n",
      "../../data/bills/2011/MA/2011-2012_187th_General_Court/people\n",
      "../../data/bills/2013/MA/2013-2014_188th_General_Court/people\n",
      "../../data/bills/2015/MA/2015-2016_189th_General_Court/people\n",
      "../../data/bills/2017/MA/2017-2018_190th_General_Court/people\n",
      "../../data/bills/2019/MA/2019-2020_191st_General_Court/people\n",
      "../../data/bills/2020/MA/2021-2022_192nd_General_Court/people\n",
      "../../data/bills/2021/MA/2023-2024_193rd_General_Court/people\n",
      "../../data/bills/2023/MA/2025-2026_194th_General_Court/people\n"
     ]
    }
   ],
   "source": [
    "for year, court in zip(years,courts):\n",
    "    full_path = path +year+\"/MA/\"+ court +\"/people\"\n",
    "    print(full_path)\n",
    "    make_people_json_df(full_path, year=year, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a78fb772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read: 2009_vote.csv\n",
      "Successfully read: 2011_vote.csv\n",
      "Successfully read: 2013_vote.csv\n",
      "Successfully read: 2015_vote.csv\n",
      "Successfully read: 2017_vote.csv\n",
      "Successfully read: 2019_vote.csv\n",
      "Error reading 2020_vote.csv: No columns to parse from file\n",
      "Error reading 2021_vote.csv: No columns to parse from file\n",
      "Error reading 2023_vote.csv: No columns to parse from file\n",
      "Successfully read: 2025_vote.csv\n",
      "\n",
      "Concatenation successful. The combined DataFrame has:\n",
      "- Number of rows: 50164\n",
      "- Number of columns: 14\n"
     ]
    }
   ],
   "source": [
    "all_politicians = []\n",
    "\n",
    "for year in years:\n",
    "    filename = f\"{year}_vote.csv\"\n",
    "    if os.path.exists(filename):\n",
    "        try:\n",
    "            df = pd.read_csv(filename)\n",
    "            all_politicians.append(df)\n",
    "            print(f\"Successfully read: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename}: {e}\")\n",
    "    else:\n",
    "        print(f\"File not found: {filename}\")\n",
    "\n",
    "if all_politicians:\n",
    "    combined_politicians_df = pd.concat(all_politicians, ignore_index=True)\n",
    "    print(\"\\nConcatenation successful. The combined DataFrame has:\")\n",
    "    print(f\"- Number of rows: {len(combined_df)}\")\n",
    "    print(f\"- Number of columns: {combined_df.shape[1]}\")\n",
    "else:\n",
    "    print(\"\\nNo CSV files were successfully read, so no DataFrame was created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2050cf36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>people_id</th>\n",
       "      <th>name</th>\n",
       "      <th>party</th>\n",
       "      <th>state_id</th>\n",
       "      <th>role</th>\n",
       "      <th>district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2388</td>\n",
       "      <td>Geraldo Alicea</td>\n",
       "      <td>D</td>\n",
       "      <td>21</td>\n",
       "      <td>Rep</td>\n",
       "      <td>HD-06-WOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2484</td>\n",
       "      <td>Kevin Murphy</td>\n",
       "      <td>D</td>\n",
       "      <td>21</td>\n",
       "      <td>Rep</td>\n",
       "      <td>HD-18-MID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2522</td>\n",
       "      <td>Christopher Speranzo</td>\n",
       "      <td>D</td>\n",
       "      <td>21</td>\n",
       "      <td>Rep</td>\n",
       "      <td>HD-03-BER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2559</td>\n",
       "      <td>Robert Hedlund</td>\n",
       "      <td>R</td>\n",
       "      <td>21</td>\n",
       "      <td>Sen</td>\n",
       "      <td>SD-PLYMOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2493</td>\n",
       "      <td>Alice Peisch</td>\n",
       "      <td>D</td>\n",
       "      <td>21</td>\n",
       "      <td>Rep</td>\n",
       "      <td>HD-14-NOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>25796</td>\n",
       "      <td>Steven Ouellette</td>\n",
       "      <td>D</td>\n",
       "      <td>21</td>\n",
       "      <td>Rep</td>\n",
       "      <td>HD-08-BRI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>22730</td>\n",
       "      <td>Rob Consalvo</td>\n",
       "      <td>D</td>\n",
       "      <td>21</td>\n",
       "      <td>Rep</td>\n",
       "      <td>HD-14-SUF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>25790</td>\n",
       "      <td>Dennis Gallagher</td>\n",
       "      <td>D</td>\n",
       "      <td>21</td>\n",
       "      <td>Rep</td>\n",
       "      <td>HD-08-PLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>24775</td>\n",
       "      <td>Priscila Sousa</td>\n",
       "      <td>D</td>\n",
       "      <td>21</td>\n",
       "      <td>Rep</td>\n",
       "      <td>HD-06-MID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>24768</td>\n",
       "      <td>Francisco Paulino</td>\n",
       "      <td>D</td>\n",
       "      <td>21</td>\n",
       "      <td>Rep</td>\n",
       "      <td>HD-16-ESS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>468 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      people_id                  name party  state_id role   district\n",
       "0          2388        Geraldo Alicea     D        21  Rep  HD-06-WOR\n",
       "1          2484          Kevin Murphy     D        21  Rep  HD-18-MID\n",
       "2          2522  Christopher Speranzo     D        21  Rep  HD-03-BER\n",
       "3          2559        Robert Hedlund     R        21  Sen  SD-PLYMOU\n",
       "4          2493          Alice Peisch     D        21  Rep  HD-14-NOR\n",
       "...         ...                   ...   ...       ...  ...        ...\n",
       "1566      25796      Steven Ouellette     D        21  Rep  HD-08-BRI\n",
       "1572      22730          Rob Consalvo     D        21  Rep  HD-14-SUF\n",
       "1574      25790      Dennis Gallagher     D        21  Rep  HD-08-PLY\n",
       "1575      24775        Priscila Sousa     D        21  Rep  HD-06-MID\n",
       "1576      24768     Francisco Paulino     D        21  Rep  HD-16-ESS\n",
       "\n",
       "[468 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_politicians_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62790e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_politicians_df = combined_politicians_df.drop_duplicates(subset=\"people_id\")\n",
    "combined_politicians_df.to_csv(\"politicians_unique.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "628110a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_votes_json_df(source: str, year, save: bool = False) -> pd.DataFrame:\n",
    "    json_files = glob.glob(os.path.join(source, \"*.json\"))\n",
    "    records = []\n",
    "    for file in json_files:\n",
    "        with open(file, \"r\") as f:\n",
    "            json_data = json.load(f)\n",
    "            json_data = json_data.get(\"roll_call\")\n",
    "            base_info = {\n",
    "                \"roll_call_id\": json_data[\"roll_call_id\"],\n",
    "                \"bill_id\": json_data[\"bill_id\"],\n",
    "                \"date\": json_data[\"date\"],\n",
    "                \"desc\": json_data[\"desc\"],\n",
    "                \"passed\": json_data[\"passed\"],\n",
    "                \"chamber\": json_data[\"chamber\"]\n",
    "            }\n",
    "            for v in json_data.get(\"votes\"):\n",
    "                record = {\n",
    "                    **base_info,\n",
    "                    \"people_id\": v[\"people_id\"],\n",
    "                    \"vote_text\": v[\"vote_text\"]\n",
    "                }\n",
    "                records.append(record)\n",
    "    df = pd.DataFrame(records)\n",
    "    if save:\n",
    "        df.to_csv(f\"{year}_roll_call.csv\", index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b179a1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/bills/2009/MA/2009-2010_186th_General_Court/vote\n",
      "../../data/bills/2011/MA/2011-2012_187th_General_Court/vote\n",
      "../../data/bills/2013/MA/2013-2014_188th_General_Court/vote\n",
      "../../data/bills/2015/MA/2015-2016_189th_General_Court/vote\n",
      "../../data/bills/2017/MA/2017-2018_190th_General_Court/vote\n",
      "../../data/bills/2019/MA/2019-2020_191st_General_Court/vote\n",
      "../../data/bills/2020/MA/2021-2022_192nd_General_Court/vote\n",
      "../../data/bills/2021/MA/2023-2024_193rd_General_Court/vote\n",
      "../../data/bills/2023/MA/2025-2026_194th_General_Court/vote\n"
     ]
    }
   ],
   "source": [
    "for year, court in zip(years, courts):\n",
    "    full_path = path +year+\"/MA/\"+ court +\"/vote\"\n",
    "    print(full_path)\n",
    "    make_votes_json_df(full_path, year=year, save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4f147ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading 2009_roll_call.csv: No columns to parse from file\n",
      "Error reading 2011_roll_call.csv: No columns to parse from file\n",
      "Error reading 2013_roll_call.csv: No columns to parse from file\n",
      "Error reading 2015_roll_call.csv: No columns to parse from file\n",
      "Successfully read: 2017_roll_call.csv\n",
      "Successfully read: 2019_roll_call.csv\n",
      "Error reading 2020_roll_call.csv: No columns to parse from file\n",
      "Error reading 2021_roll_call.csv: No columns to parse from file\n",
      "Error reading 2023_roll_call.csv: No columns to parse from file\n",
      "Error reading 2025_roll_call.csv: No columns to parse from file\n",
      "\n",
      "Concatenation successful. The combined DataFrame has:\n",
      "- Number of rows: 160222\n",
      "- Number of columns: 8\n"
     ]
    }
   ],
   "source": [
    "all_dfs = []\n",
    "\n",
    "for year in years:\n",
    "    filename = f\"{year}_roll_call.csv\"\n",
    "    if os.path.exists(filename):\n",
    "        try:\n",
    "            df = pd.read_csv(filename)\n",
    "            all_dfs.append(df)\n",
    "            print(f\"Successfully read: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename}: {e}\")\n",
    "    else:\n",
    "        print(f\"File not found: {filename}\")\n",
    "\n",
    "# Concatenate all DataFrames in the list\n",
    "if all_dfs:\n",
    "    combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    print(\"\\nConcatenation successful. The combined DataFrame has:\")\n",
    "    print(f\"- Number of rows: {len(combined_df)}\")\n",
    "    print(f\"- Number of columns: {combined_df.shape[1]}\")\n",
    "else:\n",
    "    print(\"\\nNo CSV files were successfully read, so no DataFrame was created.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wethepeople",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
